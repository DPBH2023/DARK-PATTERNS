{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAPn-1QU4MMh",
        "outputId": "213bd117-6f17-491f-e594-04d6fc649be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.931067044381492\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['category_vectorizer_rf.joblib']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from joblib import dump\n",
        "\n",
        "# Output classification column\n",
        "output_classification = \"Pattern Category\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/sample_data/dark_patterns.csv')\n",
        "\n",
        "# Remove rows with missing values in the \"Pattern String\" column\n",
        "df = df.dropna(subset=[\"Pattern String\"])\n",
        "\n",
        "# Select relevant columns\n",
        "df = df[[output_classification, \"Pattern String\"]]\n",
        "\n",
        "# Create category ID based on the output classification\n",
        "df[\"category_id\"] = df[output_classification].factorize()[0]\n",
        "\n",
        "# Create a mapping between category and its ID\n",
        "category_id_df = df[[output_classification, 'category_id']].drop_duplicates().sort_values('category_id')\n",
        "category_to_id = dict(category_id_df.values)\n",
        "id_to_category = dict(category_id_df[['category_id', output_classification]].values)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Pattern String'], df[output_classification], train_size=.3)\n",
        "\n",
        "# Define a pipeline for text classification\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),  # Convert text to a matrix of token counts\n",
        "    ('tfidf', TfidfTransformer()),  # Transform a count matrix to a normalized tf-idf representation\n",
        "    ('clf', RandomForestClassifier()),  # Random Forest classifier\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = text_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Save the classifier and vectorizer separately\n",
        "dump(text_clf.named_steps['clf'], 'category_classifier_rf.joblib')\n",
        "dump(text_clf.named_steps['vect'], 'category_vectorizer_rf.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zwcjQQV4fOk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
